{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e61404-8cc5-4b19-a180-689a3df1c7c6",
   "metadata": {},
   "source": [
    "# Cell 0: imports & config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010082d5-f982-4c14-9124-85dc8bf23ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete. Cache dir: C:\\Users\\Lenovo\\Projects\\QnA on YouTube Video - RAG\\notebooks\\.yt_rag_cache\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, hashlib, shutil, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- Config ---\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")  # expects to be set in your .env\n",
    "\n",
    "CACHE_DIR = Path(\".yt_rag_cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "TARGET_WINDOW_SECONDS = 75     # ~60â€“90s is a good default for long videos\n",
    "MMR_K = 6                      # final doc count sent to the LLM\n",
    "MMR_FETCH_K = 24               # pool for diversity\n",
    "K_CTX = 1800                   # safety cap on context size\n",
    "MODEL_NAME = \"llama-3.1-8b-instant\"  # flip to 'llama-3.1-70b-versatile' for tougher Qs\n",
    "\n",
    "print(\"âœ… Setup complete. Cache dir:\", CACHE_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324e8132-9b3b-45e9-9f06-fe51e3968d39",
   "metadata": {},
   "source": [
    "# Cell 1: utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddb55dd9-7a74-453a-add7-4857076f4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ts(sec: float) -> str:\n",
    "    sec = int(sec)\n",
    "    h = sec // 3600\n",
    "    m = (sec % 3600) // 60\n",
    "    s = sec % 60\n",
    "    return f\"{h:d}:{m:02d}:{s:02d}\" if h else f\"{m:d}:{s:02d}\"\n",
    "\n",
    "def _vid_dir(video_id: str) -> Path:\n",
    "    return CACHE_DIR / video_id\n",
    "\n",
    "def _hash_text(text: str) -> str:\n",
    "    import hashlib\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def show_citations(video_id: str, docs: List[Document]):\n",
    "    rows = []\n",
    "    for d in docs:\n",
    "        s = int(d.metadata[\"start\"])\n",
    "        w = f'{_ts(d.metadata[\"start\"])}â€“{_ts(d.metadata[\"end\"])}'\n",
    "        url = f\"https://www.youtube.com/watch?v={video_id}&t={s}s\"\n",
    "        rows.append(f\"<tr><td>{w}</td><td><a href='{url}' target='_blank'>{url}</a></td></tr>\")\n",
    "    html = \"<table><tr><th>Window</th><th>Jump Link</th></tr>\" + \"\".join(rows) + \"</table>\"\n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c1c64-1a42-4dbe-8b2e-d81a9e343940",
   "metadata": {},
   "source": [
    "# Cell 2: transcript + chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67fa8c08-2239-4622-9068-76b63286eb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transcript fetched: 4076 segments in 2.54s\n",
      "ğŸ§© Windows created: 108 (â‰ˆ75s each)\n",
      "ğŸ‘€ Preview first 2 windows:\n",
      "- [0:00â€“1:16] two one boom all right we're live thank you very much for doing this man i really appreciate it i've been absorbing your information and listening to you talk f...\n",
      "- [1:13â€“2:30] multivariate but we get summarized in pithy ways in our lives and at some deep level we know that's not true right every human basically is capable of every exp...\n",
      "ğŸ“„ Document objects: 108\n"
     ]
    }
   ],
   "source": [
    "def fetch_transcript(video_id: str, languages: List[str] = [\"en\"]) -> List[Dict[str, Any]]:\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        api = YouTubeTranscriptApi()\n",
    "        fetched = api.fetch(video_id, languages=languages)\n",
    "        data = fetched.to_raw_data()\n",
    "        print(f\"âœ… Transcript fetched: {len(data)} segments in {time.time()-t0:.2f}s\")\n",
    "        return data\n",
    "    except TranscriptsDisabled:\n",
    "        raise RuntimeError(\"No captions available for this video.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to fetch transcript: {e}\")\n",
    "\n",
    "def group_segments(segments: List[Dict[str, Any]], target_window_s: int = TARGET_WINDOW_SECONDS) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    cur, start, end = [], None, None\n",
    "    for row in segments:\n",
    "        t0 = row[\"start\"]\n",
    "        t1 = row[\"start\"] + row.get(\"duration\", 0)\n",
    "        if start is None:\n",
    "            start = t0\n",
    "        end = t1\n",
    "        cur.append(row[\"text\"].strip())\n",
    "        if (end - start) >= target_window_s:\n",
    "            out.append({\"start\": start, \"end\": end, \"text\": \" \".join(cur).strip()})\n",
    "            cur, start, end = [], None, None\n",
    "    if cur:\n",
    "        out.append({\"start\": start, \"end\": end, \"text\": \" \".join(cur).strip()})\n",
    "    print(f\"ğŸ§© Windows created: {len(out)} (â‰ˆ{target_window_s}s each)\")\n",
    "    return out\n",
    "\n",
    "def make_docs(video_id: str, windows: List[Dict[str, Any]]) -> List[Document]:\n",
    "    docs = []\n",
    "    for i, w in enumerate(windows):\n",
    "        meta = {\"video_id\": video_id, \"start\": w[\"start\"], \"end\": w[\"end\"], \"window_id\": i}\n",
    "        docs.append(Document(page_content=w[\"text\"], metadata=meta))\n",
    "    return docs\n",
    "\n",
    "# Demo on a video id (you can change it any time)\n",
    "VIDEO_ID = \"3qHkcs3kG44\"\n",
    "segments = fetch_transcript(VIDEO_ID)\n",
    "windows = group_segments(segments)\n",
    "\n",
    "print(\"ğŸ‘€ Preview first 2 windows:\")\n",
    "for w in windows[:2]:\n",
    "    print(f\"- [{_ts(w['start'])}â€“{_ts(w['end'])}] {w['text'][:160]}{'...' if len(w['text'])>160 else ''}\")\n",
    "\n",
    "docs = make_docs(VIDEO_ID, windows)\n",
    "print(f\"ğŸ“„ Document objects: {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0184ee-ba19-42f8-9a29-9b0bd59d685b",
   "metadata": {},
   "source": [
    "# Cell 3: index build/load with cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d474fde-fbff-4600-a9c5-ac437c94e86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¨ Building new index...\n",
      "âœ… Transcript fetched: 4076 segments in 2.40s\n",
      "ğŸ§© Windows created: 108 (â‰ˆ75s each)\n",
      "âœ… Index built & saved in 51.57s â†’ .yt_rag_cache\\3qHkcs3kG44\\faiss\n"
     ]
    }
   ],
   "source": [
    "def build_or_load_index(video_id: str, force_rebuild: bool = False) -> Tuple[FAISS, FastEmbedEmbeddings]:\n",
    "    vdir = _vid_dir(video_id)\n",
    "    idx_dir = vdir / \"faiss\"\n",
    "    meta_fp = vdir / \"meta.json\"\n",
    "\n",
    "    if force_rebuild and vdir.exists():\n",
    "        shutil.rmtree(vdir)\n",
    "    vdir.mkdir(exist_ok=True)\n",
    "\n",
    "    if idx_dir.exists() and meta_fp.exists():\n",
    "        t0 = time.time()\n",
    "        embeddings = FastEmbedEmbeddings()\n",
    "        vs = FAISS.load_local(str(idx_dir), embeddings, allow_dangerous_deserialization=True)\n",
    "        print(f\"âš¡ Loaded cached index in {time.time()-t0:.2f}s ({idx_dir})\")\n",
    "        return vs, embeddings\n",
    "\n",
    "    # build fresh\n",
    "    print(\"ğŸ”¨ Building new index...\")\n",
    "    t0 = time.time()\n",
    "    segs = fetch_transcript(video_id)\n",
    "    wins = group_segments(segs)\n",
    "    _docs = make_docs(video_id, wins)\n",
    "    embeddings = FastEmbedEmbeddings()\n",
    "    vs = FAISS.from_documents(_docs, embeddings)\n",
    "    FAISS.save_local(vs, str(idx_dir))\n",
    "    with open(meta_fp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"video_id\": video_id, \"num_windows\": len(wins), \"chunk_sec\": TARGET_WINDOW_SECONDS}, f)\n",
    "    print(f\"âœ… Index built & saved in {time.time()-t0:.2f}s â†’ {idx_dir}\")\n",
    "    return vs, embeddings\n",
    "\n",
    "vs, emb = build_or_load_index(VIDEO_ID, force_rebuild=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055b863c-7468-4c30-8c62-4a32751b9e7b",
   "metadata": {},
   "source": [
    "# Cell 4: retrieval helpers with visible outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a668f691-b305-4b64-b3c2-ea6795fddff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Retrieval done in 10.94s â†’ 6 docs\n",
      "  Â· [1:44:38â€“1:45:54] said no more innovation in airplanes right so we need a way to iterate on nuclea...\n",
      "  Â· [2:11:41â€“2:11:57] [Applause] [Music] [Music] i...\n",
      "  Â· [1:36:04â€“1:37:19] and that gave me some level of peace so now i have to keep asking that question ...\n",
      "  Â· [1:08:55â€“1:10:10] what happened with the university is very interesting universities first when yo...\n",
      "  Â· [1:12:37â€“1:13:54] bring it up everyone's got their minds made up already well it's what's uncomfor...\n",
      "  Â· [29:34â€“30:50] even the printing pros absolutely and what it does is it frees people up for new...\n",
      "\n",
      "ğŸ”— Quick jump links:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Window</th><th>Jump Link</th></tr><tr><td>1:44:38â€“1:45:54</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=6278s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=6278s</a></td></tr><tr><td>2:11:41â€“2:11:57</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s</a></td></tr><tr><td>1:36:04â€“1:37:19</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5764s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5764s</a></td></tr><tr><td>1:08:55â€“1:10:10</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4135s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4135s</a></td></tr><tr><td>1:12:37â€“1:13:54</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4357s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4357s</a></td></tr><tr><td>29:34â€“30:50</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=1774s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=1774s</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def simple_token_overlap_score(text: str, query: str) -> int:\n",
    "    def toks(s: str) -> set:\n",
    "        return {t for t in s.lower().split() if len(t) > 3}\n",
    "    return len(toks(text) & toks(query))\n",
    "\n",
    "def hybrid_candidates(vs: FAISS, query: str, k_fetch: int = MMR_FETCH_K) -> List[Document]:\n",
    "    pool = vs.similarity_search(query, k=k_fetch)\n",
    "    pool.sort(key=lambda d: simple_token_overlap_score(d.page_content, query), reverse=True)\n",
    "    return pool\n",
    "\n",
    "def _mmr(vs: FAISS, query: str, k: int = MMR_K, fetch_k: int = MMR_FETCH_K) -> List[Document]:\n",
    "    return vs.max_marginal_relevance_search(query, k=k, fetch_k=fetch_k)\n",
    "\n",
    "def retrieve_docs(vs: FAISS, video_id: str, query: str) -> List[Document]:\n",
    "    t0 = time.time()\n",
    "    pool = hybrid_candidates(vs, query, k_fetch=MMR_FETCH_K)\n",
    "    tmp_vs = FAISS.from_documents(pool, vs.embedding_function)  # ephemeral small VS\n",
    "    top = _mmr(tmp_vs, query, k=MMR_K, fetch_k=min(len(pool), MMR_FETCH_K))\n",
    "    print(f\"ğŸ” Retrieval done in {time.time()-t0:.2f}s â†’ {len(top)} docs\")\n",
    "    for d in top:\n",
    "        print(f\"  Â· [{_ts(d.metadata['start'])}â€“{_ts(d.metadata['end'])}] {d.page_content[:80]}...\")\n",
    "    print(\"\\nğŸ”— Quick jump links:\")\n",
    "    show_citations(video_id, top)\n",
    "    return top\n",
    "\n",
    "# Try a sample retrieval (you can change this question)\n",
    "sample_q = \"Is nuclear fusion discussed? What do they say about it?\"\n",
    "top_docs = retrieve_docs(vs, VIDEO_ID, sample_q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a0eaec-dc35-4331-93d9-93765fc2a7af",
   "metadata": {},
   "source": [
    "# Cell 5: prompt + LLM chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b61c894-6310-4664-b83b-ccbc05aa2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\", \"video_id\"],\n",
    "    template=(\n",
    "        \"Answer using ONLY the context. Include timestamped citations like [mm:ss] \"\n",
    "        \"where relevant. If not answerable, say so.\\n\\n\"\n",
    "        \"Video ID: {video_id}\\n\"\n",
    "        \"Context:\\n{context}\\n\\n\"\n",
    "        \"Question: {question}\\n\"\n",
    "    ),\n",
    ")\n",
    "llm = ChatGroq(model=MODEL_NAME, temperature=0.2)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "def _format_docs(docs: List[Document], video_id: str, max_chars: int = K_CTX) -> str:\n",
    "    parts, used = [], 0\n",
    "    for d in docs:\n",
    "        s, e = d.metadata.get(\"start\", 0), d.metadata.get(\"end\", 0)\n",
    "        tag = f\"[{_ts(s)}â€“{_ts(e)}]\"\n",
    "        text = d.page_content.strip()\n",
    "        chunk = f\"{tag} {text}\"\n",
    "        if used + len(chunk) > max_chars and parts:\n",
    "            break\n",
    "        parts.append(chunk)\n",
    "        used += len(chunk)\n",
    "    print(f\"ğŸ§µ Context length: {used} chars across {len(parts)} windows\")\n",
    "    return \"\\n\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570558fc-4e20-4313-bd5f-5b2caa9bf011",
   "metadata": {},
   "source": [
    "# Cell 6: single question\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b44b0e3-eeb5-42d5-b7f1-903c88bfa76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Loaded cached index in 2.22s (.yt_rag_cache\\3qHkcs3kG44\\faiss)\n",
      "ğŸ” Retrieval done in 10.47s â†’ 6 docs\n",
      "  Â· [1:43:25â€“1:44:40] we need one sun one solar system has got all the power we will need for a long l...\n",
      "  Â· [2:11:41â€“2:11:57] [Applause] [Music] [Music] i...\n",
      "  Â· [1:12:37â€“1:13:54] bring it up everyone's got their minds made up already well it's what's uncomfor...\n",
      "  Â· [1:08:55â€“1:10:10] what happened with the university is very interesting universities first when yo...\n",
      "  Â· [1:38:31â€“1:39:47] bacteria the parasites right the symbiotic relationship we have to our environme...\n",
      "  Â· [1:33:36â€“1:34:53] foundation of understanding a steel frame of understanding than it is to just ha...\n",
      "\n",
      "ğŸ”— Quick jump links:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Window</th><th>Jump Link</th></tr><tr><td>1:43:25â€“1:44:40</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=6205s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=6205s</a></td></tr><tr><td>2:11:41â€“2:11:57</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s</a></td></tr><tr><td>1:12:37â€“1:13:54</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4357s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4357s</a></td></tr><tr><td>1:08:55â€“1:10:10</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4135s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4135s</a></td></tr><tr><td>1:38:31â€“1:39:47</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5911s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5911s</a></td></tr><tr><td>1:33:36â€“1:34:53</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§µ Context length: 1370 chars across 2 windows\n",
      "ğŸ§  LLM answered in 0.64s\n",
      "\n",
      "=== Answer ===\n",
      "\n",
      "Yes, the topic of nuclear fusion is discussed. The speaker mentions that nuclear fusion can provide the power needed for a long time and that we are not far from making those technologies work.\n",
      "\n",
      "=== Citations ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Window</th><th>Jump Link</th></tr><tr><td>1:43:25â€“1:44:40</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=6205s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=6205s</a></td></tr><tr><td>2:11:41â€“2:11:57</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s</a></td></tr><tr><td>1:12:37â€“1:13:54</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4357s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4357s</a></td></tr><tr><td>1:08:55â€“1:10:10</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4135s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4135s</a></td></tr><tr><td>1:38:31â€“1:39:47</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5911s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5911s</a></td></tr><tr><td>1:33:36â€“1:34:53</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def answer_one(video_id: str, question: str) -> Dict[str, Any]:\n",
    "    vs, _ = build_or_load_index(video_id, force_rebuild=False)\n",
    "    top_docs = retrieve_docs(vs, video_id, question)\n",
    "    context = _format_docs(top_docs, video_id)\n",
    "    chain = (RunnableParallel({\n",
    "                \"context\": RunnableLambda(lambda _: context),\n",
    "                \"question\": RunnablePassthrough(),\n",
    "                \"video_id\": RunnableLambda(lambda _: video_id),\n",
    "            }) | PROMPT | llm | parser)\n",
    "    t0 = time.time()\n",
    "    text = chain.invoke(question).strip()\n",
    "    print(f\"ğŸ§  LLM answered in {time.time()-t0:.2f}s\")\n",
    "    print(\"\\n=== Answer ===\\n\")\n",
    "    print(text)\n",
    "    print(\"\\n=== Citations ===\")\n",
    "    show_citations(video_id, top_docs)\n",
    "    # structured return if you want to consume programmatically\n",
    "    cits = []\n",
    "    for d in top_docs:\n",
    "        s = int(d.metadata[\"start\"])\n",
    "        cits.append({\n",
    "            \"window\": f'{_ts(d.metadata[\"start\"])}â€“{_ts(d.metadata[\"end\"])}',\n",
    "            \"url\": f\"https://www.youtube.com/watch?v={video_id}&t={s}s\"\n",
    "        })\n",
    "    return {\"answer\": text, \"citations\": cits}\n",
    "\n",
    "# Try it:\n",
    "_ = answer_one(VIDEO_ID, \"Is the topic of nuclear fusion discussed? Summarize briefly.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb47d671-3069-476a-8336-cc7a31c287d2",
   "metadata": {},
   "source": [
    "# Cell 7: batch questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3a19a51-f7f7-41aa-a184-f5857b8b713e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Loaded cached index in 2.18s (.yt_rag_cache\\3qHkcs3kG44\\faiss)\n",
      "\n",
      "â€”â€”â€” Q1/3 â€”â€”â€”\n",
      "ğŸ” Retrieval done in 11.37s â†’ 6 docs\n",
      "  Â· [12:19â€“13:34] kind of person who can create wealth create business make money and my theory be...\n",
      "  Â· [2:11:41â€“2:11:57] [Applause] [Music] [Music] i...\n",
      "  Â· [35:42â€“36:59] works right we don't know we literally have no idea so most of the ai approaches...\n",
      "  Â· [1:33:36â€“1:34:53] foundation of understanding a steel frame of understanding than it is to just ha...\n",
      "  Â· [1:07:41â€“1:08:56] slouch is left right leviathan is the government why does it slouch left and i t...\n",
      "  Â· [1:29:53â€“1:31:10] turn it into an incredible tourist park and put your money where your mouth is s...\n",
      "\n",
      "ğŸ”— Quick jump links:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Window</th><th>Jump Link</th></tr><tr><td>12:19â€“13:34</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=739s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=739s</a></td></tr><tr><td>2:11:41â€“2:11:57</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=7901s</a></td></tr><tr><td>35:42â€“36:59</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=2142s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=2142s</a></td></tr><tr><td>1:33:36â€“1:34:53</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s</a></td></tr><tr><td>1:07:41â€“1:08:56</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4061s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4061s</a></td></tr><tr><td>1:29:53â€“1:31:10</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5393s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5393s</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§µ Context length: 1488 chars across 2 windows\n",
      "ğŸ§  LLM answered in 0.60s\n",
      "Answer: Three key ideas mentioned in the introduction are:\n",
      "\n",
      "1. The three basic things everybody wants: to be wealthy, happy, and fit.\n",
      "2. The importance of internal calmness and a loving household, although not as central as the initial three.\n",
      "3. The idea that these qualities can be taught and learned, rathe...\n",
      "\n",
      "â€”â€”â€” Q2/3 â€”â€”â€”\n",
      "ğŸ” Retrieval done in 10.44s â†’ 6 docs\n",
      "  Â· [30:49â€“32:04] with ubi there's a couple of problems with ubi one is you're creating a straight...\n",
      "  Â· [1:36:04â€“1:37:19] and that gave me some level of peace so now i have to keep asking that question ...\n",
      "  Â· [1:01:31â€“1:02:48] taken on liability so they're sliding down the slippery slope into ruin sloping ...\n",
      "  Â· [34:28â€“35:44] assumption that all of the computation is going at the cellular level at the neu...\n",
      "  Â· [1:15:04â€“1:16:21] why i stay out of politics largely do they drag you in though sometimes they alw...\n",
      "  Â· [1:44:38â€“1:45:54] said no more innovation in airplanes right so we need a way to iterate on nuclea...\n",
      "\n",
      "ğŸ”— Quick jump links:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Window</th><th>Jump Link</th></tr><tr><td>30:49â€“32:04</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=1849s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=1849s</a></td></tr><tr><td>1:36:04â€“1:37:19</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5764s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5764s</a></td></tr><tr><td>1:01:31â€“1:02:48</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=3691s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=3691s</a></td></tr><tr><td>34:28â€“35:44</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=2068s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=2068s</a></td></tr><tr><td>1:15:04â€“1:16:21</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=4504s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=4504s</a></td></tr><tr><td>1:44:38â€“1:45:54</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=6278s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=6278s</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§µ Context length: 1380 chars across 1 windows\n",
      "ğŸ§  LLM answered in 0.60s\n",
      "Answer: The main argument made around the halfway point is that Universal Basic Income (UBI) can lead to a slippery slope towards socialism, where the majority of people vote themselves money, potentially bankrupting the country, and also that it can lower the status and meaning of individuals who receive i...\n",
      "\n",
      "â€”â€”â€” Q3/3 â€”â€”â€”\n",
      "ğŸ” Retrieval done in 9.83s â†’ 6 docs\n",
      "  Â· [1:33:36â€“1:34:53] foundation of understanding a steel frame of understanding than it is to just ha...\n",
      "  Â· [25:52â€“27:08] time externally i'll bring that in-house if it's easy to do externally and it's ...\n",
      "  Â· [1:37:18â€“1:38:34] are all axioms these are all just stopping points saying simulation we're in a s...\n",
      "  Â· [2:03:04â€“2:04:20] someone who is smart or someone who appears smart they say smart things oh god i...\n",
      "  Â· [13:32â€“14:47] storm so there's a tweet storm with like 36 38 tweets got very famous got transl...\n",
      "  Â· [1:44:38â€“1:45:54] said no more innovation in airplanes right so we need a way to iterate on nuclea...\n",
      "\n",
      "ğŸ”— Quick jump links:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Window</th><th>Jump Link</th></tr><tr><td>1:33:36â€“1:34:53</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5616s</a></td></tr><tr><td>25:52â€“27:08</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=1552s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=1552s</a></td></tr><tr><td>1:37:18â€“1:38:34</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=5838s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=5838s</a></td></tr><tr><td>2:03:04â€“2:04:20</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=7384s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=7384s</a></td></tr><tr><td>13:32â€“14:47</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=812s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=812s</a></td></tr><tr><td>1:44:38â€“1:45:54</td><td><a href='https://www.youtube.com/watch?v=3qHkcs3kG44&t=6278s' target='_blank'>https://www.youtube.com/watch?v=3qHkcs3kG44&t=6278s</a></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§µ Context length: 1391 chars across 1 windows\n",
      "ğŸ§  LLM answered in 0.43s\n",
      "Answer: The speaker explains the following technical term:\n",
      "\n",
      "- **Scaffolding**: This refers to memorizing advanced concepts without truly understanding the underlying basics. It is a superficial approach to learning, where one may appear to be knowledgeable but lacks a deep understanding of the subject matte...\n",
      "\n",
      "âœ… Batch complete.\n"
     ]
    }
   ],
   "source": [
    "def answer_batch(video_id: str, questions: List[str]) -> List[Dict[str, Any]]:\n",
    "    vs, _ = build_or_load_index(video_id, force_rebuild=False)\n",
    "    results = []\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"\\nâ€”â€”â€” Q{i}/{len(questions)} â€”â€”â€”\")\n",
    "        top_docs = retrieve_docs(vs, video_id, q)\n",
    "        context = _format_docs(top_docs, video_id)\n",
    "        chain = (RunnableParallel({\n",
    "                    \"context\": RunnableLambda(lambda _: context),\n",
    "                    \"question\": RunnablePassthrough(),\n",
    "                    \"video_id\": RunnableLambda(lambda _: video_id),\n",
    "                }) | PROMPT | llm | parser)\n",
    "        t0 = time.time()\n",
    "        text = chain.invoke(q).strip()\n",
    "        print(f\"ğŸ§  LLM answered in {time.time()-t0:.2f}s\")\n",
    "        print(\"Answer:\", text[:300] + (\"...\" if len(text) > 300 else \"\"))\n",
    "        cits = []\n",
    "        for d in top_docs:\n",
    "            s = int(d.metadata[\"start\"])\n",
    "            cits.append({\n",
    "                \"window\": f'{_ts(d.metadata[\"start\"])}â€“{_ts(d.metadata[\"end\"])}',\n",
    "                \"url\": f\"https://www.youtube.com/watch?v={video_id}&t={s}s\"\n",
    "            })\n",
    "        results.append({\"question\": q, \"answer\": text, \"citations\": cits})\n",
    "    print(\"\\nâœ… Batch complete.\")\n",
    "    return results\n",
    "\n",
    "# Example batch run (edit these):\n",
    "batch_qs = [\n",
    "    \"List three key ideas mentioned in the introduction.\",\n",
    "    \"What is the main argument made around the halfway point?\",\n",
    "    \"Give a concise definition of any technical term the speaker explains.\",\n",
    "]\n",
    "batch_results = answer_batch(VIDEO_ID, batch_qs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbddd40e-7e69-4a61-ba80-8515727d17a2",
   "metadata": {},
   "source": [
    "# Cell 8: optional tweaks (set and re-run cells that use them)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54be3f-6b09-47fe-a303-074a38b1d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Stronger model for tricky queries:\n",
    "# MODEL_NAME = \"llama-3.1-70b-versatile\"\n",
    "\n",
    "# 2) Rebuild the index if you change chunking settings:\n",
    "# vs, emb = build_or_load_index(VIDEO_ID, force_rebuild=True)\n",
    "\n",
    "# 3) Adjust retrieval selectivity:\n",
    "# MMR_K = 6\n",
    "# MMR_FETCH_K = 24\n",
    "# K_CTX = 1800\n",
    "print(\"â„¹ï¸ Use this cell to toggle settings, then re-run Cells 3â€“7.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QNA YT (rag)",
   "language": "python",
   "name": "rag-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
