{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29edfdb-d3dc-47d5-8552-94847830c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORT: 1.23.2\n",
      "Device: GPU\n",
      "Providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import onnxruntime as ort\n",
    "\n",
    "print(\"ORT:\", ort.__version__)\n",
    "print(\"Device:\", ort.get_device())\n",
    "print(\"Providers:\", ort.get_available_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27730979-3bcd-4920-a672-66ad01d61d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** EP Error ***************\n",
      "EP Error E:\\_work\\1\\s\\onnxruntime\\python\\onnxruntime_pybind_state.cc:560 onnxruntime::python::RegisterTensorRTPluginsAsCustomOps Please install TensorRT libraries as mentioned in the GPU requirements page, make sure they're in the PATH or LD_LIBRARY_PATH, and that your GPU is supported.\n",
      " when using ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "Falling back to ['CPUExecutionProvider'] and retrying.\n",
      "****************************************\n",
      "(4096, 384) in 21.09s  →  194 chunks/sec\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "EMB_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "embedder = TextEmbedding(\n",
    "    model_name=EMB_MODEL,\n",
    "    providers=[\"TensorrtExecutionProvider\", \"CUDAExecutionProvider\", \"CPUExecutionProvider\"],\n",
    ")\n",
    "\n",
    "texts = [\"hello world\", \"gpu test\"] * 2048  # 4096 chunks to load the GPU\n",
    "t0 = time.time()\n",
    "vecs = list(embedder.embed(texts, batch_size=1024, parallel=None))\n",
    "dt = time.time() - t0\n",
    "\n",
    "arr = np.vstack(vecs).astype(\"float32\")\n",
    "print(arr.shape, \"in\", f\"{dt:.2f}s  →  {arr.shape[0]/dt:.0f} chunks/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43b06150-2c0d-473a-a271-ae777b48933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 384) in 21.14s  →  194 chunks/sec\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "EMB_MODEL = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "embedder = TextEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"],  # drop TensorRT\n",
    ")\n",
    "\n",
    "texts = [\"hello world\", \"gpu test\"] * 2048  # 4096 chunks to load the GPU\n",
    "t0 = time.time()\n",
    "vecs = list(embedder.embed(texts, batch_size=1024, parallel=None))\n",
    "dt = time.time() - t0\n",
    "\n",
    "arr = np.vstack(vecs).astype(\"float32\")\n",
    "print(arr.shape, \"in\", f\"{dt:.2f}s  →  {arr.shape[0]/dt:.0f} chunks/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3140b4-e838-43e0-9e33-59a4c0f1ecca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORT: 1.23.2\n",
      "Providers: ['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(\"ORT:\", ort.__version__)\n",
    "print(\"Providers:\", ort.get_available_providers())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97828c58-49b1-4c24-bc6d-d0cc12131d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Projects\\QnA on YouTube Video - RAG\\.venv\\Lib\\site-packages\\fastembed\\common\\onnx_model.py:109: RuntimeWarning: Attempt to set CUDAExecutionProvider failed. Current providers: ['CPUExecutionProvider'].If you are using CUDA 12.x, install onnxruntime-gpu via `pip install onnxruntime-gpu --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 384) in 21.48s  →  191 chunks/sec\n"
     ]
    }
   ],
   "source": [
    "import time, numpy as np\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "embedder = TextEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"],  # no TensorRT yet\n",
    ")\n",
    "\n",
    "texts = [\"hello world\", \"gpu test\"] * 2048\n",
    "t0 = time.time()\n",
    "vecs = list(embedder.embed(texts, batch_size=1024, parallel=None))\n",
    "dt = time.time() - t0\n",
    "arr = np.vstack(vecs).astype(\"float32\")\n",
    "print(arr.shape, \"in\", f\"{dt:.2f}s  →  {arr.shape[0]/dt:.0f} chunks/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deabdfe2-0d8b-42af-ab1a-e112e9aaaf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"ORT_LOG_SEVERITY_LEVEL\"]=\"0\"\n",
    "os.environ[\"ORT_CUDA_VERBOSE_LOGGING\"]=\"1\"\n",
    "from fastembed import TextEmbedding\n",
    "_ = TextEmbedding(model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "                  providers=[\"CUDAExecutionProvider\",\"CPUExecutionProvider\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4429753d-e3ad-4508-8170-949ed1bf6c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastembed.text.text_embedding.TextEmbedding at 0x1de43c97810>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c4506f-b170-4afa-835e-558de2134216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "(4096, 384) in 0.48s → 8550 chunks/sec\n"
     ]
    }
   ],
   "source": [
    "import time, torch, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "texts = [\"hello world\",\"gpu test\"]*2048\n",
    "t0=time.time()\n",
    "with torch.inference_mode():\n",
    "    arr = model.encode(texts, batch_size=1024, convert_to_numpy=True, normalize_embeddings=True)\n",
    "dt=time.time()-t0\n",
    "print(arr.shape,\"in\",f\"{dt:.2f}s → {arr.shape[0]/dt:.0f} chunks/sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55874e88-c27e-4715-a3cc-7a3b2ff67da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QNA YT (rag)",
   "language": "python",
   "name": "rag-uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
