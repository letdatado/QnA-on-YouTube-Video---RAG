{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa802b15-96e9-4774-a73f-913c816752e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_embedder.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def make_st_model(model_name: str = \"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = SentenceTransformer(model_name, device=device)\n",
    "    # Optional: bump max length a bit if your windows are long:\n",
    "    # model.max_seq_length = 384  # default 256; tradeoff: slight slowdown\n",
    "    return model\n",
    "\n",
    "def encode_texts(model: SentenceTransformer, texts: list[str], batch_size: int = 1024) -> np.ndarray:\n",
    "    with torch.inference_mode():\n",
    "        arr = model.encode(\n",
    "            texts,\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            normalize_embeddings=True,   # cosine => inner product\n",
    "            show_progress_bar=False,\n",
    "        )\n",
    "    return arr.astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9324e724-b507-49f8-8c43-5ed396c7395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_cache.py\n",
    "import os, hashlib, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _hash_text(t: str) -> str:\n",
    "    return hashlib.md5(t.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def embed_with_cache(model, texts: list[str], cache_dir: Path, batch_size: int = 1024) -> np.ndarray:\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    vecs: list[np.ndarray] = []\n",
    "    misses, miss_idx = [], []\n",
    "\n",
    "    # 1) Load cache hits\n",
    "    for i, t in enumerate(texts):\n",
    "        fp = cache_dir / f\"{_hash_text(t)}.npy\"\n",
    "        if fp.exists():\n",
    "            vecs.append(np.load(fp))\n",
    "        else:\n",
    "            vecs.append(None)  # placeholder\n",
    "            misses.append(t)\n",
    "            miss_idx.append(i)\n",
    "\n",
    "    # 2) Encode only misses\n",
    "    if misses:\n",
    "        from gpu_embedder import encode_texts  # local import to avoid cycles\n",
    "        new_arr = encode_texts(model, misses, batch_size=batch_size)  # (m, d)\n",
    "        for j, row in enumerate(new_arr):\n",
    "            i = miss_idx[j]\n",
    "            vecs[i] = row\n",
    "            np.save(cache_dir / f\"{_hash_text(texts[i])}.npy\", row)\n",
    "\n",
    "    # 3) Stack\n",
    "    arr = np.vstack([v for v in vecs]).astype(\"float32\")\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eeb3d5e-e7e2-4796-b1b8-51e28cdab816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, hashlib, shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "CACHE_DIR = Path(\".yt_rag_cache\")\n",
    "CACHE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Basic utils ---\n",
    "def _vid_dir(video_id: str) -> Path:\n",
    "    \"\"\"Return cache subfolder for a given YouTube video.\"\"\"\n",
    "    vdir = CACHE_DIR / video_id\n",
    "    vdir.mkdir(parents=True, exist_ok=True)\n",
    "    return vdir\n",
    "\n",
    "\n",
    "def _ts(sec: float) -> str:\n",
    "    \"\"\"Format seconds as h:mm:ss or m:ss.\"\"\"\n",
    "    sec = int(sec)\n",
    "    h, m, s = sec // 3600, (sec % 3600) // 60, sec % 60\n",
    "    return f\"{h:d}:{m:02d}:{s:02d}\" if h else f\"{m:d}:{s:02d}\"\n",
    "\n",
    "\n",
    "def _hash_text(text: str) -> str:\n",
    "    \"\"\"Return MD5 hash of text (used for caching).\"\"\"\n",
    "    return hashlib.md5(text.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "\n",
    "# --- Core helpers ---\n",
    "def fetch_transcript(video_id: str, languages: List[str] = [\"en\"]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch raw transcript segments for a YouTube video.\n",
    "    Returns a list of dicts: [{'start':..., 'duration':..., 'text':...}, ...]\n",
    "    \"\"\"\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        api = YouTubeTranscriptApi()\n",
    "        fetched = api.fetch(video_id, languages=languages)\n",
    "        data = fetched.to_raw_data()\n",
    "        print(f\"âœ… Transcript fetched: {len(data)} segments in {time.time()-t0:.2f}s\")\n",
    "        return data\n",
    "    except TranscriptsDisabled:\n",
    "        raise RuntimeError(\"âŒ No captions available for this video.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"âŒ Failed to fetch transcript: {e}\")\n",
    "\n",
    "\n",
    "def group_segments(segments: List[Dict[str, Any]],\n",
    "                   target_window_s: int = 110) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Greedy time-based grouping of small caption segments\n",
    "    into ~target_window_s second text windows.\n",
    "    \"\"\"\n",
    "    out, cur, start, end = [], [], None, None\n",
    "    for row in segments:\n",
    "        t0, t1 = row[\"start\"], row[\"start\"] + row.get(\"duration\", 0)\n",
    "        if start is None:\n",
    "            start = t0\n",
    "        end = t1\n",
    "        cur.append(row[\"text\"].strip())\n",
    "        if (end - start) >= target_window_s:\n",
    "            out.append({\"start\": start, \"end\": end, \"text\": \" \".join(cur).strip()})\n",
    "            cur, start, end = [], None, None\n",
    "    if cur:\n",
    "        out.append({\"start\": start, \"end\": end, \"text\": \" \".join(cur).strip()})\n",
    "\n",
    "    print(f\"ðŸ§© Windows created: {len(out)} (â‰ˆ{target_window_s}s each)\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def make_docs(video_id: str, windows: List[Dict[str, Any]]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Convert grouped transcript windows into LangChain Document objects.\n",
    "    Metadata includes start/end timestamps for citation links.\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "    for i, w in enumerate(windows):\n",
    "        meta = {\n",
    "            \"video_id\": video_id,\n",
    "            \"start\": w[\"start\"],\n",
    "            \"end\": w[\"end\"],\n",
    "            \"window_id\": i,\n",
    "            \"time_range\": f\"{_ts(w['start'])}â€“{_ts(w['end'])}\",\n",
    "        }\n",
    "        docs.append(Document(page_content=w[\"text\"], metadata=meta))\n",
    "    print(f\"ðŸ“„ Document objects: {len(docs)}\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fce82d2-8391-4f12-9092-e6082b6ac5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_build_st.py\n",
    "import json, shutil, time\n",
    "from pathlib import Path\n",
    "import numpy as np, faiss\n",
    "\n",
    "# reuse your existing helpers:\n",
    "#  - fetch_transcript(video_id)\n",
    "#  - group_segments(segments, target_window_s)\n",
    "#  - make_docs(video_id, windows)\n",
    "#  - _vid_dir(video_id)\n",
    "\n",
    "EMB_CACHE_ROOT = Path(\".yt_rag_cache\") / \"emb_cache_st\"\n",
    "\n",
    "def build_or_load_index_st(video_id: str,\n",
    "                           force_rebuild: bool = False,\n",
    "                           target_window_s: int = 110,\n",
    "                           batch_size: int = 1024):\n",
    "    vdir    = _vid_dir(video_id)\n",
    "    idx_dir = vdir / \"faiss_st\"\n",
    "    meta_fp = vdir / \"meta_st.json\"\n",
    "    cache_dir = EMB_CACHE_ROOT / video_id\n",
    "\n",
    "    if force_rebuild and vdir.exists():\n",
    "        shutil.rmtree(vdir, ignore_errors=True)\n",
    "    vdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Fast path: load\n",
    "    idx_path = idx_dir / \"index.faiss\"\n",
    "    metas_path = idx_dir / \"metas.jsonl\"\n",
    "    if idx_path.exists() and meta_fp.exists() and metas_path.exists():\n",
    "        index = faiss.read_index(str(idx_path))\n",
    "        metas = [json.loads(l) for l in metas_path.read_text(encoding=\"utf-8\").splitlines()]\n",
    "        return index, metas\n",
    "\n",
    "    # Build fresh\n",
    "    t0 = time.time()\n",
    "    segs = fetch_transcript(video_id)\n",
    "    wins = group_segments(segs, target_window_s=target_window_s)\n",
    "    docs = make_docs(video_id, wins)\n",
    "\n",
    "    texts = [d.page_content for d in docs]\n",
    "    model = make_st_model(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    t = time.time()\n",
    "    arr = embed_with_cache(model, texts, cache_dir=cache_dir, batch_size=batch_size)  # (n, 384)\n",
    "    t_embed = time.time() - t\n",
    "\n",
    "    # FAISS (cosine via inner product; embeddings are normalized)\n",
    "    d = arr.shape[1]\n",
    "    index = faiss.IndexFlatIP(d)\n",
    "    index.add(arr)\n",
    "\n",
    "    # Save\n",
    "    idx_dir.mkdir(parents=True, exist_ok=True)\n",
    "    faiss.write_index(index, str(idx_path))\n",
    "    with (idx_dir / \"metas.jsonl\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "        for doc in docs:\n",
    "            f.write(json.dumps(doc.metadata, ensure_ascii=False) + \"\\n\")\n",
    "    with meta_fp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\n",
    "            \"video_id\": video_id,\n",
    "            \"num_windows\": len(wins),\n",
    "            \"chunk_sec\": target_window_s,\n",
    "            \"model\": \"all-MiniLM-L6-v2\",\n",
    "            \"dim\": int(d),\n",
    "            \"embed_time_s\": round(t_embed, 3),\n",
    "        }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"âœ… Index built in {time.time()-t0:.2f}s (embed {t_embed:.2f}s) â†’ {idx_dir}\")\n",
    "    return index, [doc.metadata for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25802a35-cbf5-45c9-8808-4bb82ae53ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Transcript fetched: 4076 segments in 2.50s\n",
      "ðŸ§© Windows created: 73 (â‰ˆ110s each)\n",
      "ðŸ“„ Document objects: 73\n",
      "Example: {'video_id': '3qHkcs3kG44', 'start': 0.56, 'end': 110.79899999999999, 'window_id': 0, 'time_range': '0:00â€“1:50'} \n",
      " two one boom all right we're live thank you very much for doing this man i really appreciate it i've been absorbing your ...\n"
     ]
    }
   ],
   "source": [
    "VIDEO_ID = \"3qHkcs3kG44\"\n",
    "segs = fetch_transcript(VIDEO_ID)\n",
    "wins = group_segments(segs, target_window_s=110)\n",
    "docs = make_docs(VIDEO_ID, wins)\n",
    "print(\"Example:\", docs[0].metadata, \"\\n\", docs[0].page_content[:120], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27167445-335d-4c2d-8b7e-bf89ad759802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
